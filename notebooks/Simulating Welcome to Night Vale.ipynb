{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Welcome to Night Vale with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll be using TensorFlow to simulate text from Welcome to Night Vale. I have all of the transcripts saved to a file, so I can start by combining all of them into a large file, and studying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = r'C:\\Users\\caleb\\Documents\\Data Science\\welcome-to-night-vale\\data'\n",
    "TRANSCRIPTS_PATH = os.path.join(DATA_PATH, 'transcripts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement a model in Keras and TensorFlow for generating sequences from the training text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "with open(os.path.join(DATA_PATH, 'Welcome To Night Vale.txt'),\n",
    "          'r', encoding='utf-8') as f:\n",
    "    wtnv_text = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 - we must give praise\n",
      "\n",
      "\n",
      "don’t judge a book by its cover. judge it by the harmful messages it\n",
      "contains.\n",
      "\n",
      "\n",
      "welcome to night vale.\n",
      "\n",
      "\n",
      "the enormous glowing cloud that serves as president of the night vale\n",
      "school board announced a five-year strategic plan for the school\n",
      "district. the plan, put together over the past year by the\n",
      "twelve-member board, lays out new curriculum goals, organizational\n",
      "restructuring, and a comprehensive outline for eternal penitence\n",
      "before the mighty glow cloud.\n",
      "\n",
      "\n",
      "everyone \n"
     ]
    }
   ],
   "source": [
    "print(wtnv_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we display the alphabet on which these texts are based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#$%&'()*+,-./0123456789:;<?[\\]abcdefghijklmnopqrstuvwxyz ©º¼àáâäéîñóǜ̖̗̙̜̝̞̟̠̣̤̥̦̩̪̫̬̭̮̯̰̱̲̳̹̺̻̼͇͈͉͍͎͓͔͕͖͙͚́̂̃̄̅̆̇̉̊̋̌̍̎̏̐̑̒̓̔̽̾͂̈́͆͊͌͐͑͒͗͛ͣͤͥͦͧͨͩͪͫͬͮͯͅавгдежзиклмнопрстуцчшыьэюя–—‘’“”…‽♪♫\n"
     ]
    }
   ],
   "source": [
    "print(''.join(sorted(set(wtnv_text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(wtnv_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters: 1628468\n",
      "Total Vocab: 192\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(wtnv_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters:\", n_chars)\n",
    "print(\"Total Vocab:\", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = wtnv_text[i:i + seq_length]\n",
    "\tseq_out = wtnv_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 64 - we must give praise\n",
      "\n",
      "\n",
      "don’t judge a book by its cover. judge it by the harmful messages it\n",
      "cont\n",
      "y: a\n"
     ]
    }
   ],
   "source": [
    "print(\"X:\", ''.join([int_to_char[i] for i in dataX[0]]))\n",
    "print(\"y:\", int_to_char[dataY[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 1628368\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1628368, 100, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1628368, 192)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb_callback = TensorBoard(log_dir=os.path.join(DATA_PATH, 'logs'),\n",
    "                          histogram_freq=0.01,  \n",
    "                          write_graph=True, \n",
    "                          write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metric=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\conda\\conda\\envs\\tensorflow-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2250: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 488510 samples, validate on 1139858 samples\n",
      "Epoch 1/1\n",
      "10405s - loss: 2.9453 - val_loss: 2.8662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23134156898>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=100, validation_split=0.7, verbose=2, epochs=1, callback=tb_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(os.path.join(DATA_PATH, 'models', 'wtnv-keras-model.hd5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-env",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
